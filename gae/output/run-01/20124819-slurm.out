
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu008.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu008.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 57.98582
Epoch: 0020 train_loss= 57.98169
Epoch: 0030 train_loss= 57.98180
Epoch: 0040 train_loss= 57.94244
Epoch: 0050 train_loss= 57.87147
Epoch: 0060 train_loss= 57.86032
Epoch: 0070 train_loss= 57.85780
Epoch: 0080 train_loss= 57.85732
Epoch: 0090 train_loss= 57.85700
Epoch: 0100 train_loss= 57.85672
0.8389452945884915
Epoch: 0110 train_loss= 57.85653
Epoch: 0120 train_loss= 57.85639
Epoch: 0130 train_loss= 57.85629
Epoch: 0140 train_loss= 57.85620
Epoch: 0150 train_loss= 57.85614
Epoch: 0160 train_loss= 57.85610
Epoch: 0170 train_loss= 57.85606
Epoch: 0180 train_loss= 57.85603
Epoch: 0190 train_loss= 57.85601
Epoch: 0200 train_loss= 57.85599
0.8490599514012254
Epoch: 0210 train_loss= 57.85597
Epoch: 0220 train_loss= 57.85596
Epoch: 0230 train_loss= 57.85595
Epoch: 0240 train_loss= 57.85593
Epoch: 0250 train_loss= 57.85592
Epoch: 0260 train_loss= 57.85591
Epoch: 0270 train_loss= 57.85590
Epoch: 0280 train_loss= 57.85590
Epoch: 0290 train_loss= 57.85589
Epoch: 0300 train_loss= 57.85588
0.8519137399119227


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 19431.54688
Epoch: 0020 train_loss= 19431.54688
Epoch: 0030 train_loss= 19431.54688
Epoch: 0040 train_loss= 19431.54688
Epoch: 0050 train_loss= 19431.54688
Epoch: 0060 train_loss= 19431.54688
Epoch: 0070 train_loss= 19431.54688
Epoch: 0080 train_loss= 19431.54688
Epoch: 0090 train_loss= 19431.54688
Epoch: 0100 train_loss= 19431.54688
0.436292394655704
Epoch: 0110 train_loss= 19431.54688
Epoch: 0120 train_loss= 19431.54688
Epoch: 0130 train_loss= 19431.54688
Epoch: 0140 train_loss= 19431.54688
Epoch: 0150 train_loss= 19431.54688
Epoch: 0160 train_loss= 19431.54688
Epoch: 0170 train_loss= 19431.54688
Epoch: 0180 train_loss= 19431.54688
Epoch: 0190 train_loss= 19431.54688
Epoch: 0200 train_loss= 19431.54688
0.436292394655704
Epoch: 0210 train_loss= 19431.54688
Epoch: 0220 train_loss= 19431.54688
Epoch: 0230 train_loss= 19431.54688
Epoch: 0240 train_loss= 19431.54688
Epoch: 0250 train_loss= 19431.54688
Epoch: 0260 train_loss= 19431.54688
Epoch: 0270 train_loss= 19431.54688
Epoch: 0280 train_loss= 19431.54688
Epoch: 0290 train_loss= 19431.54688
Epoch: 0300 train_loss= 19431.54688
0.436292394655704


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 32.55663
Epoch: 0020 train_loss= 32.55565
Epoch: 0030 train_loss= 32.55562
Epoch: 0040 train_loss= 32.55561
Epoch: 0050 train_loss= 32.55561
Epoch: 0060 train_loss= 32.55560
Epoch: 0070 train_loss= 32.55560
Epoch: 0080 train_loss= 32.55560
Epoch: 0090 train_loss= 32.55560
Epoch: 0100 train_loss= 32.55560
0.851931071715342
Epoch: 0110 train_loss= 32.55559
Epoch: 0120 train_loss= 32.55559
Epoch: 0130 train_loss= 32.55559
Epoch: 0140 train_loss= 32.55558
Epoch: 0150 train_loss= 32.55558
Epoch: 0160 train_loss= 32.55557
Epoch: 0170 train_loss= 32.55556
Epoch: 0180 train_loss= 32.55556
Epoch: 0190 train_loss= 32.55557
Epoch: 0200 train_loss= 32.55556
0.8520095176499927
Epoch: 0210 train_loss= 32.55555
Epoch: 0220 train_loss= 32.55555
Epoch: 0230 train_loss= 32.55554
Epoch: 0240 train_loss= 32.55555
Epoch: 0250 train_loss= 32.55555
Epoch: 0260 train_loss= 32.55553
Epoch: 0270 train_loss= 32.55554
Epoch: 0280 train_loss= 32.55553
Epoch: 0290 train_loss= 32.55555
Epoch: 0300 train_loss= 32.55553
0.851983825749998


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 1150.57080
Epoch: 0020 train_loss= 1144.05432
Epoch: 0030 train_loss= 1130.89197
Epoch: 0040 train_loss= 1113.92517
Epoch: 0050 train_loss= 1097.90637
Epoch: 0060 train_loss= 1089.50916
Epoch: 0070 train_loss= 1081.73523
Epoch: 0080 train_loss= 1072.00867
Epoch: 0090 train_loss= 1072.70825
Epoch: 0100 train_loss= 1064.90857
0.5536723163841808
Epoch: 0110 train_loss= 1059.54175
Epoch: 0120 train_loss= 1057.68213
Epoch: 0130 train_loss= 1058.00854
Epoch: 0140 train_loss= 1055.67603
Epoch: 0150 train_loss= 1053.61719
Epoch: 0160 train_loss= 1052.02637
Epoch: 0170 train_loss= 1052.62012
Epoch: 0180 train_loss= 1051.54492
Epoch: 0190 train_loss= 1053.84729
Epoch: 0200 train_loss= 1049.33508
0.5550847457627119
Epoch: 0210 train_loss= 1048.99878
Epoch: 0220 train_loss= 1049.64026
Epoch: 0230 train_loss= 1044.80664
Epoch: 0240 train_loss= 1049.17017
Epoch: 0250 train_loss= 1043.94446
Epoch: 0260 train_loss= 1046.47241
Epoch: 0270 train_loss= 1040.83350
Epoch: 0280 train_loss= 1040.27600
Epoch: 0290 train_loss= 1039.75195
Epoch: 0300 train_loss= 1040.28516
0.5353107344632768


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 113473232.00000
Epoch: 0020 train_loss= 113426768.00000
Epoch: 0030 train_loss= 113421216.00000
Epoch: 0040 train_loss= 113421152.00000
Epoch: 0050 train_loss= 113420960.00000
Epoch: 0060 train_loss= 113420688.00000
Epoch: 0070 train_loss= 113420680.00000
Epoch: 0080 train_loss= 113420728.00000
Epoch: 0090 train_loss= 113420704.00000
Epoch: 0100 train_loss= 113421360.00000
0.6894736842105263
Epoch: 0110 train_loss= 113420616.00000
Epoch: 0120 train_loss= 113420600.00000
Epoch: 0130 train_loss= 113420624.00000
Epoch: 0140 train_loss= 113420744.00000
Epoch: 0150 train_loss= 113420616.00000
Epoch: 0160 train_loss= 113427512.00000
Epoch: 0170 train_loss= 113420984.00000
Epoch: 0180 train_loss= 113420664.00000
Epoch: 0190 train_loss= 113421384.00000
Epoch: 0200 train_loss= 113420624.00000
0.690922531046718
Epoch: 0210 train_loss= 113423664.00000
Epoch: 0220 train_loss= 113420592.00000
Epoch: 0230 train_loss= 113420000.00000
Epoch: 0240 train_loss= 113436656.00000
Epoch: 0250 train_loss= 113431712.00000
Epoch: 0260 train_loss= 113425976.00000
Epoch: 0270 train_loss= 113422024.00000
Epoch: 0280 train_loss= 113420368.00000
Epoch: 0290 train_loss= 113420592.00000
Epoch: 0300 train_loss= 113420496.00000
0.6899319929036074


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 39.28342
Epoch: 0020 train_loss= 39.28340
Epoch: 0030 train_loss= 39.28340
Epoch: 0040 train_loss= 39.28340
Epoch: 0050 train_loss= 39.28340
Epoch: 0060 train_loss= 39.28340
Epoch: 0070 train_loss= 39.28340
Epoch: 0080 train_loss= 39.28340
Epoch: 0090 train_loss= 39.28340
Epoch: 0100 train_loss= 39.28340
0.8107644546700916
Epoch: 0110 train_loss= 39.28340
Epoch: 0120 train_loss= 39.28339
Epoch: 0130 train_loss= 39.28339
Epoch: 0140 train_loss= 39.28339
Epoch: 0150 train_loss= 39.28339
Epoch: 0160 train_loss= 39.28339
Epoch: 0170 train_loss= 39.28339
Epoch: 0180 train_loss= 39.28338
Epoch: 0190 Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
train_loss= 39.28338
Epoch: 0200 train_loss= 39.28337
0.8105810233701561
Epoch: 0210 train_loss= 39.28337
Epoch: 0220 train_loss= 39.28336
Epoch: 0230 train_loss= 39.28338
Epoch: 0240 train_loss= 39.28336
Epoch: 0250 train_loss= 39.28335
Epoch: 0260 train_loss= 39.28334
Epoch: 0270 train_loss= 39.28334
Epoch: 0280 train_loss= 39.28333
Epoch: 0290 train_loss= 39.28333
Epoch: 0300 train_loss= 39.28332
0.8108186646075295


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 39.33485
Epoch: 0020 train_loss= 39.33486
Epoch: 0030 train_loss= 39.33486
Epoch: 0040 train_loss= 39.33486
Epoch: 0050 train_loss= 39.33486
Epoch: 0060 train_loss= 39.33485
Epoch: 0070 train_loss= 39.33486
Epoch: 0080 train_loss= 39.33486
Epoch: 0090 train_loss= 39.33486
Epoch: 0100 train_loss= 39.33486
0.8954013161693999
Epoch: 0110 train_loss= 39.33486
Epoch: 0120 train_loss= 39.33486
Epoch: 0130 train_loss= 39.33486
Epoch: 0140 train_loss= 39.33486
Epoch: 0150 train_loss= 39.33486
Epoch: 0160 train_loss= 39.33486
Epoch: 0170 train_loss= 39.33486
Epoch: 0180 train_loss= 39.33486
Epoch: 0190 train_loss= 39.33486
Epoch: 0200 train_loss= 39.33486
0.895401630021317
Epoch: 0210 train_loss= 39.33486
Epoch: 0220 train_loss= 39.33486
Epoch: 0230 train_loss= 39.33486
Epoch: 0240 train_loss= 39.33486
Epoch: 0250 train_loss= 39.33486
Epoch: 0260 train_loss= 39.33486
Epoch: 0270 train_loss= 39.33486
Epoch: 0280 train_loss= 39.33486
Epoch: 0290 train_loss= 39.33486
Epoch: 0300 train_loss= 39.33486
0.8954042977626124


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.1, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 39.87055
Epoch: 0020 train_loss= nan
Epoch: 0030 train_loss= nan
Epoch: 0040 train_loss= nan
Epoch: 0050 train_loss= nan
Epoch: 0060 train_loss= nan
Epoch: 0070 train_loss= nan
Epoch: 0080 train_loss= nan
Epoch: 0090 train_loss= nan
Epoch: 0100 train_loss= nan
