
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu066.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu066.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 7.56927
Epoch: 0020 train_loss= 7.26584
Epoch: 0030 train_loss= 7.23003
Epoch: 0040 train_loss= 7.18317
Epoch: 0050 train_loss= 7.18261
Epoch: 0060 train_loss= 7.17878
Epoch: 0070 train_loss= 7.17776
Epoch: 0080 train_loss= 7.17728
Epoch: 0090 train_loss= 7.17644
Epoch: 0100 train_loss= 7.17558
0.8300525020031941
Epoch: 0110 train_loss= 7.17478
Epoch: 0120 train_loss= 7.17406
Epoch: 0130 train_loss= 7.17342
Epoch: 0140 train_loss= 7.17283
Epoch: 0150 train_loss= 7.17232
Epoch: 0160 train_loss= 7.17191
Epoch: 0170 train_loss= 7.17157
Epoch: 0180 train_loss= 7.17128
Epoch: 0190 train_loss= 7.17102
Epoch: 0200 train_loss= 7.17079
0.832446492715447
Epoch: 0210 train_loss= 7.17054
Epoch: 0220 train_loss= 7.17019
Epoch: 0230 train_loss= 7.16977
Epoch: 0240 train_loss= 7.16935
Epoch: 0250 train_loss= 7.16899
Epoch: 0260 train_loss= 7.16871
Epoch: 0270 train_loss= 7.16849
Epoch: 0280 train_loss= 7.16825
Epoch: 0290 train_loss= 7.16817
Epoch: 0300 train_loss= 7.16793
0.8418899268492019


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 166280.35938
Epoch: 0020 train_loss= 166255.76562
Epoch: 0030 train_loss= 166252.09375
Epoch: 0040 train_loss= 166251.15625
Epoch: 0050 train_loss= 166250.48438
Epoch: 0060 train_loss= 166249.26562
Epoch: 0070 train_loss= 166249.50000
Epoch: 0080 train_loss= 166249.96875
Epoch: 0090 train_loss= 166249.48438
Epoch: 0100 train_loss= 166249.43750
0.6261048304213772
Epoch: 0110 train_loss= 166249.40625
Epoch: 0120 train_loss= 166250.06250
Epoch: 0130 train_loss= 166249.40625
Epoch: 0140 train_loss= 166249.32812
Epoch: 0150 train_loss= 166249.40625
Epoch: 0160 train_loss= 166250.10938
Epoch: 0170 train_loss= 166251.67188
Epoch: 0180 train_loss= 166250.20312
Epoch: 0190 train_loss= 166252.26562
Epoch: 0200 train_loss= 166252.71875
0.6274023638232271
Epoch: 0210 train_loss= 166250.03125
Epoch: 0220 train_loss= 166252.23438
Epoch: 0230 train_loss= 166251.23438
Epoch: 0240 train_loss= 166250.50000
Epoch: 0250 train_loss= 166250.01562
Epoch: 0260 train_loss= 166249.32812
Epoch: 0270 train_loss= 166249.26562
Epoch: 0280 train_loss= 166249.60938
Epoch: 0290 train_loss= 166250.31250
Epoch: 0300 train_loss= 166249.45312
0.6270811921891059


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 4.66083
Epoch: 0020 train_loss= 4.66031
Epoch: 0030 train_loss= 4.66010
Epoch: 0040 train_loss= 4.66002
Epoch: 0050 train_loss= 4.65996
Epoch: 0060 train_loss= 4.65988
Epoch: 0070 train_loss= 4.65989
Epoch: 0080 train_loss= 4.65980
Epoch: 0090 train_loss= 4.65974
Epoch: 0100 train_loss= 4.65967
0.7802506707298692
Epoch: 0110 train_loss= 4.65964
Epoch: 0120 train_loss= 4.65961
Epoch: 0130 train_loss= 4.65958
Epoch: 0140 train_loss= 4.65961
Epoch: 0150 train_loss= 4.65959
Epoch: 0160 train_loss= 4.65955
Epoch: 0170 train_loss= 4.65952
Epoch: 0180 train_loss= 4.65949
Epoch: 0190 train_loss= 4.65946
Epoch: 0200 train_loss= 4.65949
0.7802212106845419
Epoch: 0210 train_loss= 4.65945
Epoch: 0220 train_loss= 4.65941
Epoch: 0230 train_loss= 4.65942
Epoch: 0240 train_loss= 4.65935
Epoch: 0250 train_loss= 4.65935
Epoch: 0260 train_loss= 4.65930
Epoch: 0270 train_loss= 4.65930
Epoch: 0280 train_loss= 4.65932
Epoch: 0290 train_loss= 4.65925
Epoch: 0300 train_loss= 4.65919
0.7801533840685555


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 10258.93652
Epoch: 0020 train_loss= 10182.75000
Epoch: 0030 train_loss= 10050.56152
Epoch: 0040 train_loss= 9916.55273
Epoch: 0050 train_loss= 9839.96094
Epoch: 0060 train_loss= 9789.63867
Epoch: 0070 train_loss= 9697.16895
Epoch: 0080 train_loss= 9775.71582
Epoch: 0090 train_loss= 9692.36035
Epoch: 0100 train_loss= 9632.95215
0.5480225988700566
Epoch: 0110 train_loss= 9585.29688
Epoch: 0120 train_loss= 9589.19336
Epoch: 0130 train_loss= 9626.58496
Epoch: 0140 train_loss= 9511.43359
Epoch: 0150 train_loss= 9556.89648
Epoch: 0160 train_loss= 9487.07324
Epoch: 0170 train_loss= 9541.31836
Epoch: 0180 train_loss= 9464.65723
Epoch: 0190 train_loss= 9493.87598
Epoch: 0200 train_loss= 9424.52441
0.5466101694915254
Epoch: 0210 train_loss= 9445.75293
Epoch: 0220 train_loss= 9415.11328
Epoch: 0230 train_loss= 9406.74512
Epoch: 0240 train_loss= 9388.25195
Epoch: 0250 train_loss= 9375.54883
Epoch: 0260 train_loss= 9376.45410
Epoch: 0270 train_loss= 9411.26465
Epoch: 0280 train_loss= 9378.89551
Epoch: 0290 train_loss= 9351.01465
Epoch: 0300 train_loss= 9331.15039
0.5296610169491526


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 1021366400.00000
Epoch: 0020 train_loss= 1020800320.00000
Epoch: 0030 train_loss= 1020796480.00000
Epoch: 0040 train_loss= 1020785664.00000
Epoch: 0050 train_loss= 1020787072.00000
Epoch: 0060 train_loss= 1020786112.00000
Epoch: 0070 train_loss= 1020785088.00000
Epoch: 0080 train_loss= 1020786048.00000
Epoch: 0090 train_loss= 1020785536.00000
Epoch: 0100 train_loss= 1020784640.00000
0.6902720283855707
Epoch: 0110 train_loss= 1020786048.00000
Epoch: 0120 train_loss= 1020784640.00000
Epoch: 0130 train_loss= 1020785088.00000
Epoch: 0140 train_loss= 1020786944.00000
Epoch: 0150 train_loss= 1020783744.00000
Epoch: 0160 train_loss= 1020785088.00000
Epoch: 0170 train_loss= 1020782784.00000
Epoch: 0180 train_loss= 1020781312.00000
Epoch: 0190 train_loss= 1020786048.00000
Epoch: 0200 train_loss= 1020782336.00000
0.6901094027202839
Epoch: 0210 train_loss= 1020823104.00000
Epoch: 0220 train_loss= 1020803648.00000
Epoch: 0230 train_loss= 1020790144.00000
Epoch: 0240 train_loss= 1020781312.00000
Epoch: 0250 train_loss= 1020845824.00000
Epoch: 0260 train_loss= 1020824384.00000
Epoch: 0270 train_loss= 1020784384.00000
Epoch: 0280 train_loss= 1020782080.00000
Epoch: 0290 train_loss= 1020779328.00000
Epoch: 0300 train_loss= 1020777152.00000
0.6903015966883501


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 5.41480
Epoch: 0020 train_loss= 5.41474
Epoch: 0030 train_loss= 5.41472
Epoch: 0040 train_loss= 5.41469
Epoch: 0050 train_loss= 5.41466
Epoch: 0060 train_loss= 5.41461
Epoch: 0070 train_loss= 5.41453
Epoch: 0080 train_loss= 5.41441
Epoch: 0090 train_loss= 5.41430
Epoch: 0100 train_loss= 5.41423
0.7488485115905259
Epoch: 0110 train_loss= 5.41408
Epoch: 0120 train_loss= 5.41429
Epoch: 0130 train_loss= 5.41404
Epoch: 0140 train_loss= 5.41387
Epoch: 0150 train_loss= 5.41373
Epoch: 0160 train_loss= 5.41359
Epoch: 0170 train_loss= 5.41351
Epoch: 0180 train_loss= 5.41329
Epoch: 0190 train_lossTraceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
= 5.41309
Epoch: 0200 train_loss= 5.41302
0.747368139054793
Epoch: 0210 train_loss= 5.41269
Epoch: 0220 train_loss= 5.41253
Epoch: 0230 train_loss= 5.41216
Epoch: 0240 train_loss= 5.41209
Epoch: 0250 train_loss= 5.41167
Epoch: 0260 train_loss= 5.41140
Epoch: 0270 train_loss= 5.41104
Epoch: 0280 train_loss= 5.41093
Epoch: 0290 train_loss= 5.41128
Epoch: 0300 train_loss= 5.41072
0.7462054619663708


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 5.44844
Epoch: 0020 train_loss= 5.42389
Epoch: 0030 train_loss= 5.39469
Epoch: 0040 train_loss= 5.38366
Epoch: 0050 train_loss= 5.38018
Epoch: 0060 train_loss= 5.38013
Epoch: 0070 train_loss= 5.37961
Epoch: 0080 train_loss= 5.37962
Epoch: 0090 train_loss= 5.37957
Epoch: 0100 train_loss= 5.37956
0.487855343140578
Epoch: 0110 train_loss= 5.37956
Epoch: 0120 train_loss= 5.37955
Epoch: 0130 train_loss= 5.37955
Epoch: 0140 train_loss= 5.37955
Epoch: 0150 train_loss= 5.37955
Epoch: 0160 train_loss= 5.37955
Epoch: 0170 train_loss= 5.37955
Epoch: 0180 train_loss= 5.37955
Epoch: 0190 train_loss= 5.37955
Epoch: 0200 train_loss= 5.37955
0.48776495378844376
Epoch: 0210 train_loss= 5.37955
Epoch: 0220 train_loss= 5.37955
Epoch: 0230 train_loss= 5.37955
Epoch: 0240 train_loss= 5.37955
Epoch: 0250 train_loss= 5.37955
Epoch: 0260 train_loss= 5.37955
Epoch: 0270 train_loss= 5.37955
Epoch: 0280 train_loss= 5.37955
Epoch: 0290 train_loss= 5.37955
Epoch: 0300 train_loss= 5.37955
0.48776165834331386


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.9, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 10.68215
Epoch: 0020 train_loss= 10.67999
Epoch: 0030 train_loss= 10.68000
Epoch: 0040 train_loss= 10.67987
Epoch: 0050 train_loss= 10.67944
Epoch: 0060 train_loss= 10.67900
Epoch: 0070 train_loss= 10.67866
Epoch: 0080 train_loss= 10.67975
Epoch: 0090 train_loss= 10.67868
Epoch: 0100 train_loss= 10.67780
