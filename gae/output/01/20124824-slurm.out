
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu065.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu065.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 26.77262
Epoch: 0020 train_loss= 26.32764
Epoch: 0030 train_loss= 26.26871
Epoch: 0040 train_loss= 26.24831
Epoch: 0050 train_loss= 26.24356
Epoch: 0060 train_loss= 26.23889
Epoch: 0070 train_loss= 26.18947
Epoch: 0080 train_loss= 26.19080
Epoch: 0090 train_loss= 26.18647
Epoch: 0100 train_loss= 26.18656
0.8361675600863511
Epoch: 0110 train_loss= 26.18594
Epoch: 0120 train_loss= 26.18581
Epoch: 0130 train_loss= 26.18557
Epoch: 0140 train_loss= 26.18541
Epoch: 0150 train_loss= 26.18521
Epoch: 0160 train_loss= 26.18501
Epoch: 0170 train_loss= 26.18478
Epoch: 0180 train_loss= 26.18455
Epoch: 0190 train_loss= 26.18426
Epoch: 0200 train_loss= 26.18368
0.8261253782700066
Epoch: 0210 train_loss= 26.18312
Epoch: 0220 train_loss= 26.18265
Epoch: 0230 train_loss= 26.18225
Epoch: 0240 train_loss= 26.18185
Epoch: 0250 train_loss= 26.18146
Epoch: 0260 train_loss= 26.18111
Epoch: 0270 train_loss= 26.18079
Epoch: 0280 train_loss= 26.18050
Epoch: 0290 train_loss= 26.18024
Epoch: 0300 train_loss= 26.18000
0.8424660425430861


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 110909.13281
Epoch: 0020 train_loss= 110867.13281
Epoch: 0030 train_loss= 110859.86719
Epoch: 0040 train_loss= 110846.79688
Epoch: 0050 train_loss= 110845.55469
Epoch: 0060 train_loss= 110846.56250
Epoch: 0070 train_loss= 110845.57812
Epoch: 0080 train_loss= 110845.41406
Epoch: 0090 train_loss= 110849.28125
Epoch: 0100 train_loss= 110848.98438
0.6254624871531347
Epoch: 0110 train_loss= 110854.14844
Epoch: 0120 train_loss= 110846.68750
Epoch: 0130 train_loss= 110845.50781
Epoch: 0140 train_loss= 110845.46094
Epoch: 0150 train_loss= 110846.17969
Epoch: 0160 train_loss= 110846.09375
Epoch: 0170 train_loss= 110848.20312
Epoch: 0180 train_loss= 110850.80469
Epoch: 0190 train_loss= 110869.72656
Epoch: 0200 train_loss= 110851.93750
0.6266058581706064
Epoch: 0210 train_loss= 110847.80469
Epoch: 0220 train_loss= 110845.65625
Epoch: 0230 train_loss= 110846.25781
Epoch: 0240 train_loss= 110845.38281
Epoch: 0250 train_loss= 110845.94531
Epoch: 0260 train_loss= 110846.38281
Epoch: 0270 train_loss= 110864.07031
Epoch: 0280 train_loss= 110847.03906
Epoch: 0290 train_loss= 110846.24219
Epoch: 0300 train_loss= 110849.32031
0.6246145940390544


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 15.12092
Epoch: 0020 train_loss= 15.12106
Epoch: 0030 train_loss= 15.12062
Epoch: 0040 train_loss= 15.12056
Epoch: 0050 train_loss= 15.12045
Epoch: 0060 train_loss= 15.12045
Epoch: 0070 train_loss= 15.12043
Epoch: 0080 train_loss= 15.12043
Epoch: 0090 train_loss= 15.12043
Epoch: 0100 train_loss= 15.12043
0.785166045036873
Epoch: 0110 train_loss= 15.12042
Epoch: 0120 train_loss= 15.12042
Epoch: 0130 train_loss= 15.12042
Epoch: 0140 train_loss= 15.12042
Epoch: 0150 train_loss= 15.12043
Epoch: 0160 train_loss= 15.12042
Epoch: 0170 train_loss= 15.12042
Epoch: 0180 train_loss= 15.12041
Epoch: 0190 train_loss= 15.12041
Epoch: 0200 train_loss= 15.12041
0.7851735813275382
Epoch: 0210 train_loss= 15.12041
Epoch: 0220 train_loss= 15.12041
Epoch: 0230 train_loss= 15.12041
Epoch: 0240 train_loss= 15.12041
Epoch: 0250 train_loss= 15.12041
Epoch: 0260 train_loss= 15.12041
Epoch: 0270 train_loss= 15.12078
Epoch: 0280 train_loss= 15.12043
Epoch: 0290 train_loss= 15.12043
Epoch: 0300 train_loss= 15.12042
0.7851766643555375


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 6822.43457
Epoch: 0020 train_loss= 6813.44775
Epoch: 0030 train_loss= 6791.10742
Epoch: 0040 train_loss= 6746.57959
Epoch: 0050 train_loss= 6676.98193
Epoch: 0060 train_loss= 6595.91309
Epoch: 0070 train_loss= 6543.58691
Epoch: 0080 train_loss= 6508.21582
Epoch: 0090 train_loss= 6460.35986
Epoch: 0100 train_loss= 6446.10791
0.5621468926553672
Epoch: 0110 train_loss= 6408.53320
Epoch: 0120 train_loss= 6387.88818
Epoch: 0130 train_loss= 6380.18457
Epoch: 0140 train_loss= 6408.13330
Epoch: 0150 train_loss= 6384.15576
Epoch: 0160 train_loss= 6366.96533
Epoch: 0170 train_loss= 6353.58887
Epoch: 0180 train_loss= 6360.95459
Epoch: 0190 train_loss= 6333.42139
Epoch: 0200 train_loss= 6318.07422
0.5564971751412429
Epoch: 0210 train_loss= 6286.71875
Epoch: 0220 train_loss= 6273.96094
Epoch: 0230 train_loss= 6257.06543
Epoch: 0240 train_loss= 6255.66309
Epoch: 0250 train_loss= 6243.28906
Epoch: 0260 train_loss= 6303.41260
Epoch: 0270 train_loss= 6227.10791
Epoch: 0280 train_loss= 6197.62061
Epoch: 0290 train_loss= 6263.43896
Epoch: 0300 train_loss= 6221.08740
0.5353107344632768


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 681312640.00000
Epoch: 0020 train_loss= 680806848.00000
Epoch: 0030 train_loss= 680674560.00000
Epoch: 0040 train_loss= 680550080.00000
Epoch: 0050 train_loss= 680524544.00000
Epoch: 0060 train_loss= 680565376.00000
Epoch: 0070 train_loss= 680529600.00000
Epoch: 0080 train_loss= 680527040.00000
Epoch: 0090 train_loss= 680528064.00000
Epoch: 0100 train_loss= 680524032.00000
0.6901389710230633
Epoch: 0110 train_loss= 680523968.00000
Epoch: 0120 train_loss= 680523456.00000
Epoch: 0130 train_loss= 680523904.00000
Epoch: 0140 train_loss= 680523392.00000
Epoch: 0150 train_loss= 680523776.00000
Epoch: 0160 train_loss= 680523264.00000
Epoch: 0170 train_loss= 680523776.00000
Epoch: 0180 train_loss= 680521984.00000
Epoch: 0190 train_loss= 680521600.00000
Epoch: 0200 train_loss= 680521088.00000
0.6902424600827912
Epoch: 0210 train_loss= 680520576.00000
Epoch: 0220 train_loss= 680528192.00000
Epoch: 0230 train_loss= 680520576.00000
Epoch: 0240 train_loss= 680522752.00000
Epoch: 0250 train_loss= 680520384.00000
Epoch: 0260 train_loss= 680519232.00000
Epoch: 0270 train_loss= 680519680.00000
Epoch: 0280 train_loss= 680519296.00000
Epoch: 0290 train_loss= 681298432.00000
Epoch: 0300 train_loss= 680581184.00000
0.6872560615020697


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 18.11552
Epoch: 0020 train_loss= 18.11546
Epoch: 0030 train_loss= 18.11541
Epoch: 0040 train_loss= 18.11542
Epoch: 0050 train_loss= 18.11541
Epoch: 0060 train_loss= 18.11541
Epoch: 0070 train_loss= 18.11539
Epoch: 0080 train_loss= 18.11542
Epoch: 0090 train_loss= 18.11539
Epoch: 0100 train_loss= 18.11538
0.7539190317853034
Epoch: 0110 train_loss= 18.11536
Epoch: 0120 train_loss= 18.11533
Epoch: 0130 train_loss= 18.11536
Epoch: 0140 train_loss= 18.11527
Epoch: 0150 train_loss= 18.11522
Epoch: 0160 train_loss= 18.11535
Epoch: 0170 train_loss= 18.11531
Epoch: 018Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
0 train_loss= 18.11524
Epoch: 0190 train_loss= 18.11526
Epoch: 0200 train_loss= 18.11519
0.7532236002332289
Epoch: 0210 train_loss= 18.11513
Epoch: 0220 train_loss= 18.11506
Epoch: 0230 train_loss= 18.11492
Epoch: 0240 train_loss= 18.11484
Epoch: 0250 train_loss= 18.11477
Epoch: 0260 train_loss= 18.11467
Epoch: 0270 train_loss= 18.11457
Epoch: 0280 train_loss= 18.11445
Epoch: 0290 train_loss= 18.11435
Epoch: 0300 train_loss= 18.11419
0.7528988133696835


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 18.40116
Epoch: 0020 train_loss= 18.23598
Epoch: 0030 train_loss= 18.22172
Epoch: 0040 train_loss= 18.21714
Epoch: 0050 train_loss= 18.21408
Epoch: 0060 train_loss= 18.21329
Epoch: 0070 train_loss= 18.21320
Epoch: 0080 train_loss= 18.21314
Epoch: 0090 train_loss= 18.21314
Epoch: 0100 train_loss= 18.21313
0.5088311652442898
Epoch: 0110 train_loss= 18.21313
Epoch: 0120 train_loss= 18.21312
Epoch: 0130 train_loss= 18.21312
Epoch: 0140 train_loss= 18.21312
Epoch: 0150 train_loss= 18.21312
Epoch: 0160 train_loss= 18.21312
Epoch: 0170 train_loss= 18.21312
Epoch: 0180 train_loss= 18.21312
Epoch: 0190 train_loss= 18.21312
Epoch: 0200 train_loss= 18.21312
0.5087523884130893
Epoch: 0210 train_loss= 18.21312
Epoch: 0220 train_loss= 18.21312
Epoch: 0230 train_loss= 18.21312
Epoch: 0240 train_loss= 18.21312
Epoch: 0250 train_loss= 18.21312
Epoch: 0260 train_loss= 18.21312
Epoch: 0270 train_loss= 18.21312
Epoch: 0280 train_loss= 18.21312
Epoch: 0290 train_loss= 18.21312
Epoch: 0300 train_loss= 18.21312
0.508752545339048


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.6, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 21.62724
Epoch: 0020 train_loss= 21.62564
Epoch: 0030 train_loss= 21.62508
Epoch: 0040 train_loss= 21.62562
Epoch: 0050 train_loss= 21.62518
Epoch: 0060 train_loss= 21.62504
Epoch: 0070 train_loss= 21.62502
Epoch: 0080 train_loss= 21.62499
Epoch: 0090 train_loss= 21.62497
Epoch: 0100 train_loss= 21.62493
