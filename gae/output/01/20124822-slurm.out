
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu010.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu010.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 39.25630
Epoch: 0020 train_loss= 38.99549
Epoch: 0030 train_loss= 38.94775
Epoch: 0040 train_loss= 38.93638
Epoch: 0050 train_loss= 38.93452
Epoch: 0060 train_loss= 38.93216
Epoch: 0070 train_loss= 38.93190
Epoch: 0080 train_loss= 38.93159
Epoch: 0090 train_loss= 38.93142
Epoch: 0100 train_loss= 38.93132
0.8029844856138447
Epoch: 0110 train_loss= 38.93122
Epoch: 0120 train_loss= 38.93111
Epoch: 0130 train_loss= 38.93101
Epoch: 0140 train_loss= 38.93090
Epoch: 0150 train_loss= 38.93079
Epoch: 0160 train_loss= 38.93067
Epoch: 0170 train_loss= 38.93056
Epoch: 0180 train_loss= 38.93044
Epoch: 0190 train_loss= 38.93033
Epoch: 0200 train_loss= 38.93022
0.8016373033280181
Epoch: 0210 train_loss= 38.93011
Epoch: 0220 train_loss= 38.93002
Epoch: 0230 train_loss= 38.92992
Epoch: 0240 train_loss= 38.92983
Epoch: 0250 train_loss= 38.92974
Epoch: 0260 train_loss= 38.92966
Epoch: 0270 train_loss= 38.92958
Epoch: 0280 train_loss= 38.92949
Epoch: 0290 train_loss= 38.92941
Epoch: 0300 train_loss= 38.92933
0.803575127886526


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 73940.11719
Epoch: 0020 train_loss= 73909.59375
Epoch: 0030 train_loss= 73909.69531
Epoch: 0040 train_loss= 73909.63281
Epoch: 0050 train_loss= 73909.58594
Epoch: 0060 train_loss= 73909.49219
Epoch: 0070 train_loss= 73909.69531
Epoch: 0080 train_loss= 73909.99219
Epoch: 0090 train_loss= 73910.22656
Epoch: 0100 train_loss= 73909.51562
0.6261819116135663
Epoch: 0110 train_loss= 73909.51562
Epoch: 0120 train_loss= 73909.92969
Epoch: 0130 train_loss= 73910.38281
Epoch: 0140 train_loss= 73910.96094
Epoch: 0150 train_loss= 73910.73438
Epoch: 0160 train_loss= 73909.58594
Epoch: 0170 train_loss= 73909.89844
Epoch: 0180 train_loss= 73909.64844
Epoch: 0190 train_loss= 73909.53125
Epoch: 0200 train_loss= 73910.33594
0.6249614594039055
Epoch: 0210 train_loss= 73911.37500
Epoch: 0220 train_loss= 73911.85156
Epoch: 0230 train_loss= 73912.66406
Epoch: 0240 train_loss= 73910.33594
Epoch: 0250 train_loss= 73909.55469
Epoch: 0260 train_loss= 73910.96094
Epoch: 0270 train_loss= 73909.92188
Epoch: 0280 train_loss= 73910.23438
Epoch: 0290 train_loss= 73909.44531
Epoch: 0300 train_loss= 73910.58594
0.6228802672147996


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 22.09530
Epoch: 0020 train_loss= 22.09474
Epoch: 0030 train_loss= 22.09472
Epoch: 0040 train_loss= 22.09454
Epoch: 0050 train_loss= 22.09452
Epoch: 0060 train_loss= 22.09448
Epoch: 0070 train_loss= 22.09446
Epoch: 0080 train_loss= 22.09443
Epoch: 0090 train_loss= 22.09440
Epoch: 0100 train_loss= 22.09437
0.7925200944913826
Epoch: 0110 train_loss= 22.09435
Epoch: 0120 train_loss= 22.09448
Epoch: 0130 train_loss= 22.09440
Epoch: 0140 train_loss= 22.09433
Epoch: 0150 train_loss= 22.09429
Epoch: 0160 train_loss= 22.09427
Epoch: 0170 train_loss= 22.09426
Epoch: 0180 train_loss= 22.09424
Epoch: 0190 train_loss= 22.09431
Epoch: 0200 train_loss= 22.09435
0.7923762198514117
Epoch: 0210 train_loss= 22.09422
Epoch: 0220 train_loss= 22.09421
Epoch: 0230 train_loss= 22.09419
Epoch: 0240 train_loss= 22.09419
Epoch: 0250 train_loss= 22.09418
Epoch: 0260 train_loss= 22.09417
Epoch: 0270 train_loss= 22.09416
Epoch: 0280 train_loss= 22.09415
Epoch: 0290 train_loss= 22.09415
Epoch: 0300 train_loss= 22.09411
0.7925050219100523


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 4640.20508
Epoch: 0020 train_loss= 4631.32227
Epoch: 0030 train_loss= 4626.12842
Epoch: 0040 train_loss= 4620.04736
Epoch: 0050 train_loss= 4618.46289
Epoch: 0060 train_loss= 4616.81836
Epoch: 0070 train_loss= 4616.30957
Epoch: 0080 train_loss= 4615.83545
Epoch: 0090 train_loss= 4614.49854
Epoch: 0100 train_loss= 4612.51025
0.4731638418079096
Epoch: 0110 train_loss= 4611.90137
Epoch: 0120 train_loss= 4611.58887
Epoch: 0130 train_loss= 4609.93311
Epoch: 0140 train_loss= 4610.24902
Epoch: 0150 train_loss= 4607.89111
Epoch: 0160 train_loss= 4606.42383
Epoch: 0170 train_loss= 4605.46094
Epoch: 0180 train_loss= 4601.47607
Epoch: 0190 train_loss= 4604.51562
Epoch: 0200 train_loss= 4601.34766
0.47457627118644063
Epoch: 0210 train_loss= 4598.97656
Epoch: 0220 train_loss= 4597.12695
Epoch: 0230 train_loss= 4595.55273
Epoch: 0240 train_loss= 4593.68555
Epoch: 0250 train_loss= 4592.16162
Epoch: 0260 train_loss= 4592.33838
Epoch: 0270 train_loss= 4590.09131
Epoch: 0280 train_loss= 4590.50488
Epoch: 0290 train_loss= 4589.49805
Epoch: 0300 train_loss= 4589.40479
0.4731638418079096


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 453997536.00000
Epoch: 0020 train_loss= 453684352.00000
Epoch: 0030 train_loss= 453682720.00000
Epoch: 0040 train_loss= 453682528.00000
Epoch: 0050 train_loss= 453683456.00000
Epoch: 0060 train_loss= 453686624.00000
Epoch: 0070 train_loss= 453683072.00000
Epoch: 0080 train_loss= 453682112.00000
Epoch: 0090 train_loss= 453682272.00000
Epoch: 0100 train_loss= 453682976.00000
0.6908042578356003
Epoch: 0110 train_loss= 453682272.00000
Epoch: 0120 train_loss= 453681696.00000
Epoch: 0130 train_loss= 453681248.00000
Epoch: 0140 train_loss= 453693568.00000
Epoch: 0150 train_loss= 453683200.00000
Epoch: 0160 train_loss= 453682688.00000
Epoch: 0170 train_loss= 453681344.00000
Epoch: 0180 train_loss= 453680928.00000
Epoch: 0190 train_loss= 453678592.00000
Epoch: 0200 train_loss= 453679808.00000
0.6901981076286221
Epoch: 0210 train_loss= 453757376.00000
Epoch: 0220 train_loss= 453687744.00000
Epoch: 0230 train_loss= 453697984.00000
Epoch: 0240 train_loss= 453682368.00000
Epoch: 0250 train_loss= 453680576.00000
Epoch: 0260 train_loss= 453680896.00000
Epoch: 0270 train_loss= 453680672.00000
Epoch: 0280 train_loss= 453679904.00000
Epoch: 0290 train_loss= 459180416.00000
Epoch: 0300 train_loss= 459180384.00000
0.7310762862211708


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 26.58264
Epoch: 0020 train_loss= 26.58261
Epoch: 0030 train_loss= 26.58259
Epoch: 0040 train_loss= 26.58260
Epoch: 0050 train_loss= 26.58260
Epoch: 0060 train_loss= 26.58259
Epoch: 0070 train_loss= 26.58258
Epoch: 0080 train_loss= 26.58257
Epoch: 0090 train_loss= 26.58259
Epoch: 0100 train_loss= 26.58257
0.7597818995540286
Epoch: 0110 train_loss= 26.58254
Epoch: 0120 train_loss= 26.58253
Epoch: 0130 train_loss= 26.58252
Epoch: 0140 train_loss= 26.58269
Epoch: 0150 train_loss= 26.58254
Epoch: 0160 train_loss= 26.58252
Epoch: 0170 train_loss= 26.58248
Epoch: 0180 train_loss= 26.58246
Epoch:Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
 0190 train_loss= 26.58241
Epoch: 0200 train_loss= 26.58255
0.7589454276123989
Epoch: 0210 train_loss= 26.58243
Epoch: 0220 train_loss= 26.58236
Epoch: 0230 train_loss= 26.58231
Epoch: 0240 train_loss= 26.58227
Epoch: 0250 train_loss= 26.58223
Epoch: 0260 train_loss= 26.58220
Epoch: 0270 train_loss= 26.58229
Epoch: 0280 train_loss= 26.58213
Epoch: 0290 train_loss= 26.58201
Epoch: 0300 train_loss= 26.58191
0.7572764234048253


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 26.70087
Epoch: 0020 train_loss= 26.62550
Epoch: 0030 train_loss= 26.61028
Epoch: 0040 train_loss= 26.60811
Epoch: 0050 train_loss= 26.60697
Epoch: 0060 train_loss= 26.60674
Epoch: 0070 train_loss= 26.60657
Epoch: 0080 train_loss= 26.60656
Epoch: 0090 train_loss= 26.60655
Epoch: 0100 train_loss= 26.60654
0.5277942550034272
Epoch: 0110 train_loss= 26.60654
Epoch: 0120 train_loss= 26.60654
Epoch: 0130 train_loss= 26.60654
Epoch: 0140 train_loss= 26.60654
Epoch: 0150 train_loss= 26.60654
Epoch: 0160 train_loss= 26.60654
Epoch: 0170 train_loss= 26.60654
Epoch: 0180 train_loss= 26.60654
Epoch: 0190 train_loss= 26.60654
Epoch: 0200 train_loss= 26.60654
0.5277817009267419
Epoch: 0210 train_loss= 26.60654
Epoch: 0220 train_loss= 26.60654
Epoch: 0230 train_loss= 26.60654
Epoch: 0240 train_loss= 26.60654
Epoch: 0250 train_loss= 26.60654
Epoch: 0260 train_loss= 26.60654
Epoch: 0270 train_loss= 26.60654
Epoch: 0280 train_loss= 26.60654
Epoch: 0290 train_loss= 26.60654
Epoch: 0300 train_loss= 26.60654
0.5277799747411978


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.4, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 28.92339
Epoch: 0020 train_loss= 28.92336
Epoch: 0030 train_loss= 28.92233
Epoch: 0040 train_loss= 28.92227
Epoch: 0050 train_loss= 28.92214
Epoch: 0060 train_loss= 28.92245
Epoch: 0070 train_loss= 28.92210
Epoch: 0080 train_loss= 28.92221
Epoch: 0090 train_loss= nan
Epoch: 0100 train_loss= nan
