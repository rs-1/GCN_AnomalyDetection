
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu020.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu020.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 1.38245
Epoch: 0020 train_loss= 1.25356
Epoch: 0030 train_loss= 1.13643
Epoch: 0040 train_loss= 0.99093
Epoch: 0050 train_loss= 0.98078
Epoch: 0060 train_loss= 0.95773
Epoch: 0070 train_loss= 0.88375
Epoch: 0080 train_loss= 0.88269
Epoch: 0090 train_loss= 0.88004
Epoch: 0100 train_loss= 0.87850
0.8328313944210358
Epoch: 0110 train_loss= 0.87780
Epoch: 0120 train_loss= 0.87731
Epoch: 0130 train_loss= 0.87671
Epoch: 0140 train_loss= 0.87599
Epoch: 0150 train_loss= 0.87526
Epoch: 0160 train_loss= 0.87455
Epoch: 0170 train_loss= 0.87395
Epoch: 0180 train_loss= 0.87345
Epoch: 0190 train_loss= 0.87291
Epoch: 0200 train_loss= 0.87238
0.8361044010481031
Epoch: 0210 train_loss= 0.87190
Epoch: 0220 train_loss= 0.87143
Epoch: 0230 train_loss= 0.87099
Epoch: 0240 train_loss= 0.87067
Epoch: 0250 train_loss= 0.87019
Epoch: 0260 train_loss= 0.86985
Epoch: 0270 train_loss= 0.86941
Epoch: 0280 train_loss= 0.86912
Epoch: 0290 train_loss= 0.86920
Epoch: 0300 train_loss= 0.86856
0.8335239332754235


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 184724.32812
Epoch: 0020 train_loss= 184727.04688
Epoch: 0030 train_loss= 184717.82812
Epoch: 0040 train_loss= 184717.46875
Epoch: 0050 train_loss= 184720.48438
Epoch: 0060 train_loss= 184717.45312
Epoch: 0070 train_loss= 184717.37500
Epoch: 0080 train_loss= 184717.37500
Epoch: 0090 train_loss= 184719.53125
Epoch: 0100 train_loss= 184727.62500
0.6232656731757451
Epoch: 0110 train_loss= 184747.26562
Epoch: 0120 train_loss= 184724.96875
Epoch: 0130 train_loss= 184719.29688
Epoch: 0140 train_loss= 184758.84375
Epoch: 0150 train_loss= 184729.70312
Epoch: 0160 train_loss= 184742.81250
Epoch: 0170 train_loss= 184719.28125
Epoch: 0180 train_loss= 184736.35938
Epoch: 0190 train_loss= 184717.45312
Epoch: 0200 train_loss= 184745.23438
0.6263360739979446
Epoch: 0210 train_loss= 184721.57812
Epoch: 0220 train_loss= 184726.70312
Epoch: 0230 train_loss= 184729.92188
Epoch: 0240 train_loss= 184723.31250
Epoch: 0250 train_loss= 184724.46875
Epoch: 0260 train_loss= 184717.39062
Epoch: 0270 train_loss= 184732.76562
Epoch: 0280 train_loss= 184727.06250
Epoch: 0290 train_loss= 184717.26562
Epoch: 0300 train_loss= 184719.43750
0.6269527235354573


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 1.17380
Epoch: 0020 train_loss= 1.17363
Epoch: 0030 train_loss= 1.17358
Epoch: 0040 train_loss= 1.17355
Epoch: 0050 train_loss= 1.17353
Epoch: 0060 train_loss= 1.17350
Epoch: 0070 train_loss= 1.17344
Epoch: 0080 train_loss= 1.17335
Epoch: 0090 train_loss= 1.17327
Epoch: 0100 train_loss= 1.17324
0.77917743442742
Epoch: 0110 train_loss= 1.17320
Epoch: 0120 train_loss= 1.17312
Epoch: 0130 train_loss= 1.17302
Epoch: 0140 train_loss= 1.17298
Epoch: 0150 train_loss= 1.17286
Epoch: 0160 train_loss= 1.17279
Epoch: 0170 train_loss= 1.17274
Epoch: 0180 train_loss= 1.17270
Epoch: 0190 train_loss= 1.17293
Epoch: 0200 train_loss= 1.17266
0.77916133417009
Epoch: 0210 train_loss= 1.17247
Epoch: 0220 train_loss= 1.17238
Epoch: 0230 train_loss= 1.17247
Epoch: 0240 train_loss= 1.17233
Epoch: 0250 train_loss= 1.17227
Epoch: 0260 train_loss= 1.17221
Epoch: 0270 train_loss= 1.17217
Epoch: 0280 train_loss= 1.17216
Epoch: 0290 train_loss= 1.17211
Epoch: 0300 train_loss= 1.17210
0.779116116426099


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 11356.11328
Epoch: 0020 train_loss= 11301.88477
Epoch: 0030 train_loss= 11184.90918
Epoch: 0040 train_loss= 10975.56152
Epoch: 0050 train_loss= 10957.34082
Epoch: 0060 train_loss= 10833.07520
Epoch: 0070 train_loss= 10791.47363
Epoch: 0080 train_loss= 10771.29004
Epoch: 0090 train_loss= 10732.65723
Epoch: 0100 train_loss= 11001.99707
0.5409604519774012
Epoch: 0110 train_loss= 10844.11816
Epoch: 0120 train_loss= 10627.78418
Epoch: 0130 train_loss= 10577.96582
Epoch: 0140 train_loss= 10769.02930
Epoch: 0150 train_loss= 10801.64355
Epoch: 0160 train_loss= 10644.49707
Epoch: 0170 train_loss= 10783.82520
Epoch: 0180 train_loss= 10687.16992
Epoch: 0190 train_loss= 10671.24512
Epoch: 0200 train_loss= 10613.30664
0.5127118644067796
Epoch: 0210 train_loss= 10505.08691
Epoch: 0220 train_loss= 10627.35645
Epoch: 0230 train_loss= 10489.85840
Epoch: 0240 train_loss= 10555.85547
Epoch: 0250 train_loss= 10492.49805
Epoch: 0260 train_loss= 10426.89941
Epoch: 0270 train_loss= 10611.23340
Epoch: 0280 train_loss= 10506.37109
Epoch: 0290 train_loss= 10445.64746
Epoch: 0300 train_loss= 10445.85059
0.49858757062146886


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 1134456832.00000
Epoch: 0020 train_loss= 1134219136.00000
Epoch: 0030 train_loss= 1134232832.00000
Epoch: 0040 train_loss= 1134222976.00000
Epoch: 0050 train_loss= 1134300160.00000
Epoch: 0060 train_loss= 1134216960.00000
Epoch: 0070 train_loss= 1134207232.00000
Epoch: 0080 train_loss= 1134210048.00000
Epoch: 0090 train_loss= 1134205312.00000
Epoch: 0100 train_loss= 1134205568.00000
0.6905972797161443
Epoch: 0110 train_loss= 1134205568.00000
Epoch: 0120 train_loss= 1134204928.00000
Epoch: 0130 train_loss= 1134205696.00000
Epoch: 0140 train_loss= 1134204928.00000
Epoch: 0150 train_loss= 1134204800.00000
Epoch: 0160 train_loss= 1134204672.00000
Epoch: 0170 train_loss= 1134204544.00000
Epoch: 0180 train_loss= 1134204416.00000
Epoch: 0190 train_loss= 1134204544.00000
Epoch: 0200 train_loss= 1134203136.00000
0.6903311649911295
Epoch: 0210 train_loss= 1134202368.00000
Epoch: 0220 train_loss= 1134200704.00000
Epoch: 0230 train_loss= 1134205056.00000
Epoch: 0240 train_loss= 1134202880.00000
Epoch: 0250 train_loss= 1134203008.00000
Epoch: 0260 train_loss= 1134202752.00000
Epoch: 0270 train_loss= 1134198912.00000
Epoch: 0280 train_loss= 1134251520.00000
Epoch: 0290 train_loss= 1134201856.00000
Epoch: 0300 train_loss= 1134194176.00000
0.6906564163217032


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 1.18126
Epoch: 0020 train_loss= 1.18119
Epoch: 0030 train_loss= 1.18114
Epoch: 0040 train_loss= 1.18109
Epoch: 0050 train_loss= 1.18097
Epoch: 0060 train_loss= 1.18093
Epoch: 0070 train_loss= 1.18084
Epoch: 0080 train_loss= 1.18076
Epoch: 0090 train_loss= 1.18063
Epoch: 0100 train_loss= 1.18062
0.7483133460453535
Epoch: 0110 train_loss= 1.18049
Epoch: 0120 train_loss= 1.18031
Epoch: 0130 train_loss= 1.18024
Epoch: 0140 train_loss= 1.18001
Epoch: 0150 train_loss= 1.17977
Epoch: 0160 train_loss= 1.17961
Epoch: 0170 train_loss= 1.17927
Epoch: 0180 train_loss= 1.1789Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
4
Epoch: 0190 train_loss= 1.18026
Epoch: 0200 train_loss= 1.17969
0.7458007784799155
Epoch: 0210 train_loss= 1.17920
Epoch: 0220 train_loss= 1.17870
Epoch: 0230 train_loss= 1.17815
Epoch: 0240 train_loss= 1.17758
Epoch: 0250 train_loss= 1.17689
Epoch: 0260 train_loss= 1.17625
Epoch: 0270 train_loss= 1.17587
Epoch: 0280 train_loss= 1.17496
Epoch: 0290 train_loss= 1.17431
Epoch: 0300 train_loss= 1.17419
0.7447509337031376


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 1.27462
Epoch: 0020 train_loss= 1.26435
Epoch: 0030 train_loss= 1.25968
Epoch: 0040 train_loss= 1.25884
Epoch: 0050 train_loss= 1.25836
Epoch: 0060 train_loss= 1.25821
Epoch: 0070 train_loss= 1.25816
Epoch: 0080 train_loss= 1.25814
Epoch: 0090 train_loss= 1.25814
Epoch: 0100 train_loss= 1.25813
0.49094129211578874
Epoch: 0110 train_loss= 1.25813
Epoch: 0120 train_loss= 1.25813
Epoch: 0130 train_loss= 1.25813
Epoch: 0140 train_loss= 1.25813
Epoch: 0150 train_loss= 1.25813
Epoch: 0160 train_loss= 1.25813
Epoch: 0170 train_loss= 1.25813
Epoch: 0180 train_loss= 1.25813
Epoch: 0190 train_loss= 1.25813
Epoch: 0200 train_loss= 1.25813
0.490965458713408
Epoch: 0210 train_loss= 1.25813
Epoch: 0220 train_loss= 1.25813
Epoch: 0230 train_loss= 1.25813
Epoch: 0240 train_loss= 1.25813
Epoch: 0250 train_loss= 1.25813
Epoch: 0260 train_loss= 1.25813
Epoch: 0270 train_loss= 1.25813
Epoch: 0280 train_loss= 1.25813
Epoch: 0290 train_loss= 1.25813
Epoch: 0300 train_loss= 1.25813
0.4909627909721123


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 1.0, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 7.03332
Epoch: 0020 train_loss= 7.03278
Epoch: 0030 train_loss= 7.03256
Epoch: 0040 train_loss= 7.03220
Epoch: 0050 train_loss= 7.03176
Epoch: 0060 train_loss= 7.03148
Epoch: 0070 train_loss= 7.03138
Epoch: 0080 train_loss= 7.03130
Epoch: 0090 train_loss= 7.03126
Epoch: 0100 train_loss= 7.03124
