
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu015.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu015.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 20.42373
Epoch: 0020 train_loss= 20.14161
Epoch: 0030 train_loss= 20.06940
Epoch: 0040 train_loss= 20.05663
Epoch: 0050 train_loss= 20.05252
Epoch: 0060 train_loss= 20.05109
Epoch: 0070 train_loss= 20.05010
Epoch: 0080 train_loss= 20.04993
Epoch: 0090 train_loss= 20.04966
Epoch: 0100 train_loss= 20.04945
0.7912304833308561
Epoch: 0110 train_loss= 20.04924
Epoch: 0120 train_loss= 20.04904
Epoch: 0130 train_loss= 20.04884
Epoch: 0140 train_loss= 20.04862
Epoch: 0150 train_loss= 20.04839
Epoch: 0160 train_loss= 20.04815
Epoch: 0170 train_loss= 20.04787
Epoch: 0180 train_loss= 20.04755
Epoch: 0190 train_loss= 20.04719
Epoch: 0200 train_loss= 20.04683
0.8032034895789693
Epoch: 0210 train_loss= 20.04647
Epoch: 0220 train_loss= 20.04613
Epoch: 0230 train_loss= 20.04575
Epoch: 0240 train_loss= 20.04535
Epoch: 0250 train_loss= 20.04499
Epoch: 0260 train_loss= 20.04468
Epoch: 0270 train_loss= 20.04442
Epoch: 0280 train_loss= 20.04421
Epoch: 0290 train_loss= 20.04401
Epoch: 0300 train_loss= 20.04385
0.8100328237521774


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 129502.02344
Epoch: 0020 train_loss= 129318.78906
Epoch: 0030 train_loss= 129328.39062
Epoch: 0040 train_loss= 129313.75781
Epoch: 0050 train_loss= 129313.55469
Epoch: 0060 train_loss= 129313.48438
Epoch: 0070 train_loss= 129313.51562
Epoch: 0080 train_loss= 129313.89062
Epoch: 0090 train_loss= 129313.78125
Epoch: 0100 train_loss= 129314.03125
0.6258735868448099
Epoch: 0110 train_loss= 129313.71875
Epoch: 0120 train_loss= 129313.51562
Epoch: 0130 train_loss= 129313.46094
Epoch: 0140 train_loss= 129313.42188
Epoch: 0150 train_loss= 129313.48438
Epoch: 0160 train_loss= 129313.45312
Epoch: 0170 train_loss= 129313.97656
Epoch: 0180 train_loss= 129313.42188
Epoch: 0190 train_loss= 129313.45312
Epoch: 0200 train_loss= 129315.55469
0.6241264131551902
Epoch: 0210 train_loss= 129314.53906
Epoch: 0220 train_loss= 129314.89844
Epoch: 0230 train_loss= 129313.48438
Epoch: 0240 train_loss= 129314.82812
Epoch: 0250 train_loss= 129314.10156
Epoch: 0260 train_loss= 129313.40625
Epoch: 0270 train_loss= 129315.53125
Epoch: 0280 train_loss= 129313.39062
Epoch: 0290 train_loss= 129315.25000
Epoch: 0300 train_loss= 129315.59375
0.6256294964028777


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 11.63429
Epoch: 0020 train_loss= 11.63406
Epoch: 0030 train_loss= 11.63366
Epoch: 0040 train_loss= 11.63346
Epoch: 0050 train_loss= 11.63341
Epoch: 0060 train_loss= 11.63339
Epoch: 0070 train_loss= 11.63339
Epoch: 0080 train_loss= 11.63338
Epoch: 0090 train_loss= 11.63338
Epoch: 0100 train_loss= 11.63337
0.7830757520532966
Epoch: 0110 train_loss= 11.63336
Epoch: 0120 train_loss= 11.63334
Epoch: 0130 train_loss= 11.63326
Epoch: 0140 train_loss= 11.63338
Epoch: 0150 train_loss= 11.63333
Epoch: 0160 train_loss= 11.63320
Epoch: 0170 train_loss= 11.63314
Epoch: 0180 train_loss= 11.63308
Epoch: 0190 train_loss= 11.63304
Epoch: 0200 train_loss= 11.63298
0.7830349875719717
Epoch: 0210 train_loss= 11.63286
Epoch: 0220 train_loss= 11.63278
Epoch: 0230 train_loss= 11.63331
Epoch: 0240 train_loss= 11.63286
Epoch: 0250 train_loss= 11.63273
Epoch: 0260 train_loss= 11.63265
Epoch: 0270 train_loss= 11.63259
Epoch: 0280 train_loss= 11.63255
Epoch: 0290 train_loss= 11.63267
Epoch: 0300 train_loss= 11.63254
0.7829020748093318


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 7984.91406
Epoch: 0020 train_loss= 7904.95654
Epoch: 0030 train_loss= 7800.63965
Epoch: 0040 train_loss= 7698.94336
Epoch: 0050 train_loss= 7627.16260
Epoch: 0060 train_loss= 7575.66748
Epoch: 0070 train_loss= 7544.82324
Epoch: 0080 train_loss= 7537.05615
Epoch: 0090 train_loss= 7537.86621
Epoch: 0100 train_loss= 7518.85205
0.5536723163841808
Epoch: 0110 train_loss= 7431.73096
Epoch: 0120 train_loss= 7432.17578
Epoch: 0130 train_loss= 7431.77979
Epoch: 0140 train_loss= 7393.27783
Epoch: 0150 train_loss= 7428.56689
Epoch: 0160 train_loss= 7380.94043
Epoch: 0170 train_loss= 7338.86768
Epoch: 0180 train_loss= 7322.96826
Epoch: 0190 train_loss= 7325.63721
Epoch: 0200 train_loss= 7409.66602
0.5338983050847457
Epoch: 0210 train_loss= 7398.19629
Epoch: 0220 train_loss= 7382.61475
Epoch: 0230 train_loss= 7340.38721
Epoch: 0240 train_loss= 7303.00049
Epoch: 0250 train_loss= 7291.84033
Epoch: 0260 train_loss= 7308.92725
Epoch: 0270 train_loss= 7284.24561
Epoch: 0280 train_loss= 7299.92578
Epoch: 0290 train_loss= 7319.20850
Epoch: 0300 train_loss= 7376.29199
0.5


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 793959296.00000
Epoch: 0020 train_loss= 793945856.00000
Epoch: 0030 train_loss= 793946176.00000
Epoch: 0040 train_loss= 793950336.00000
Epoch: 0050 train_loss= 793945472.00000
Epoch: 0060 train_loss= 793951424.00000
Epoch: 0070 train_loss= 793947840.00000
Epoch: 0080 train_loss= 793944256.00000
Epoch: 0090 train_loss= 793945152.00000
Epoch: 0100 train_loss= 793944704.00000
0.6907746895328208
Epoch: 0110 train_loss= 793944000.00000
Epoch: 0120 train_loss= 793944704.00000
Epoch: 0130 train_loss= 793944128.00000
Epoch: 0140 train_loss= 793943104.00000
Epoch: 0150 train_loss= 793941376.00000
Epoch: 0160 train_loss= 793940736.00000
Epoch: 0170 train_loss= 793940864.00000
Epoch: 0180 train_loss= 793937984.00000
Epoch: 0190 train_loss= 793949632.00000
Epoch: 0200 train_loss= 793940288.00000
0.6902424600827912
Epoch: 0210 train_loss= 793938432.00000
Epoch: 0220 train_loss= 793965184.00000
Epoch: 0230 train_loss= 796364608.00000
Epoch: 0240 train_loss= 794310016.00000
Epoch: 0250 train_loss= 794068160.00000
Epoch: 0260 train_loss= 793948544.00000
Epoch: 0270 train_loss= 793950336.00000
Epoch: 0280 train_loss= 793945600.00000
Epoch: 0290 train_loss= 793944128.00000
Epoch: 0300 train_loss= 793941120.00000
0.6900206978119456


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 13.88196
Epoch: 0020 train_loss= 13.88187
Epoch: 0030 train_loss= 13.88187
Epoch: 0040 train_loss= 13.88192
Epoch: 0050 train_loss= 13.88185
Epoch: 0060 train_loss= 13.88185
Epoch: 0070 train_loss= 13.88185
Epoch: 0080 train_loss= 13.88185
Epoch: 0090 train_loss= 13.88184
Epoch: 0100 train_loss= 13.88184
0.7522886363994515
Epoch: 0110 train_loss= 13.88183
Epoch: 0120 train_loss= 13.88182
Epoch: 0130 train_loss= 13.88176
Epoch: 0140 train_loss= 13.88181
Epoch: 0150 train_loss= 13.88175
Epoch: 0160 train_loss= 13.88169
Epoch: 0170 train_loss= 13.88163
Epoch: 0180 train_loss= Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
13.88158
Epoch: 0190 train_loss= 13.88180
Epoch: 0200 train_loss= 13.88174
0.7517842003246293
Epoch: 0210 train_loss= 13.88169
Epoch: 0220 train_loss= 13.88163
Epoch: 0230 train_loss= 13.88155
Epoch: 0240 train_loss= 13.88163
Epoch: 0250 train_loss= 13.88155
Epoch: 0260 train_loss= 13.88150
Epoch: 0270 train_loss= 13.88145
Epoch: 0280 train_loss= 13.88140
Epoch: 0290 train_loss= 13.88134
Epoch: 0300 train_loss= 13.88127
0.7515043257639031


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 14.19062
Epoch: 0020 train_loss= 13.90579
Epoch: 0030 train_loss= 13.85752
Epoch: 0040 train_loss= 13.84790
Epoch: 0050 train_loss= 13.84499
Epoch: 0060 train_loss= 13.84445
Epoch: 0070 train_loss= 13.84405
Epoch: 0080 train_loss= 13.84401
Epoch: 0090 train_loss= 13.84392
Epoch: 0100 train_loss= 13.84392
0.48686733730544324
Epoch: 0110 train_loss= 13.84392
Epoch: 0120 train_loss= 13.84391
Epoch: 0130 train_loss= 13.84391
Epoch: 0140 train_loss= 13.84391
Epoch: 0150 train_loss= 13.84391
Epoch: 0160 train_loss= 13.84391
Epoch: 0170 train_loss= 13.84391
Epoch: 0180 train_loss= 13.84391
Epoch: 0190 train_loss= 13.84391
Epoch: 0200 train_loss= 13.84391
0.4867552921710267
Epoch: 0210 train_loss= 13.84391
Epoch: 0220 train_loss= 13.84391
Epoch: 0230 train_loss= 13.84391
Epoch: 0240 train_loss= 13.84391
Epoch: 0250 train_loss= 13.84391
Epoch: 0260 train_loss= 13.84391
Epoch: 0270 train_loss= 13.84391
Epoch: 0280 train_loss= 13.84391
Epoch: 0290 train_loss= 13.84391
Epoch: 0300 train_loss= 13.84391
0.48675372291144103


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 17.97800
Epoch: 0020 train_loss= 17.97909
Epoch: 0030 train_loss= 17.97762
Epoch: 0040 train_loss= 17.97681
Epoch: 0050 train_loss= 17.97655
Epoch: 0060 train_loss= 17.97646
Epoch: 0070 train_loss= 17.97798
Epoch: 0080 train_loss= 17.97670
Epoch: 0090 train_loss= 17.97646
Epoch: 0100 train_loss= 17.97643
