
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu065.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu065.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 14.18504
Epoch: 0020 train_loss= 13.53612
Epoch: 0030 train_loss= 13.50405
Epoch: 0040 train_loss= 13.48835
Epoch: 0050 train_loss= 13.48712
Epoch: 0060 train_loss= 13.48555
Epoch: 0070 train_loss= 13.48507
Epoch: 0080 train_loss= 13.48476
Epoch: 0090 train_loss= 13.48451
Epoch: 0100 train_loss= 13.48424
0.8598210936029579
Epoch: 0110 train_loss= 13.48399
Epoch: 0120 train_loss= 13.48374
Epoch: 0130 train_loss= 13.48350
Epoch: 0140 train_loss= 13.48328
Epoch: 0150 train_loss= 13.48305
Epoch: 0160 train_loss= 13.48283
Epoch: 0170 train_loss= 13.48259
Epoch: 0180 train_loss= 13.48235
Epoch: 0190 train_loss= 13.48210
Epoch: 0200 train_loss= 13.48184
0.8564915070041268
Epoch: 0210 train_loss= 13.48158
Epoch: 0220 train_loss= 13.48123
Epoch: 0230 train_loss= 13.48078
Epoch: 0240 train_loss= 13.48026
Epoch: 0250 train_loss= 13.47977
Epoch: 0260 train_loss= 13.47935
Epoch: 0270 train_loss= 13.47904
Epoch: 0280 train_loss= 13.47876
Epoch: 0290 train_loss= 13.47851
Epoch: 0300 train_loss= 13.47827
0.8581738532529221


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 147892.81250
Epoch: 0020 train_loss= 147809.84375
Epoch: 0030 train_loss= 147784.64062
Epoch: 0040 train_loss= 147786.56250
Epoch: 0050 train_loss= 147781.37500
Epoch: 0060 train_loss= 147782.75000
Epoch: 0070 train_loss= 147782.64062
Epoch: 0080 train_loss= 147782.15625
Epoch: 0090 train_loss= 147783.35938
Epoch: 0100 train_loss= 147784.71875
0.6251927029804727
Epoch: 0110 train_loss= 147782.28125
Epoch: 0120 train_loss= 147783.56250
Epoch: 0130 train_loss= 147782.25000
Epoch: 0140 train_loss= 147786.12500
Epoch: 0150 train_loss= 147786.12500
Epoch: 0160 train_loss= 147783.48438
Epoch: 0170 train_loss= 147781.48438
Epoch: 0180 train_loss= 147782.57812
Epoch: 0190 train_loss= 147781.37500
Epoch: 0200 train_loss= 147783.03125
0.6266572456320658
Epoch: 0210 train_loss= 147781.37500
Epoch: 0220 train_loss= 147783.56250
Epoch: 0230 train_loss= 147781.50000
Epoch: 0240 train_loss= 147782.26562
Epoch: 0250 train_loss= 147782.12500
Epoch: 0260 train_loss= 147787.17188
Epoch: 0270 train_loss= 147790.17188
Epoch: 0280 train_loss= 147787.28125
Epoch: 0290 train_loss= 147781.46875
Epoch: 0300 train_loss= 147788.01562
0.6264131551901336


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 8.14801
Epoch: 0020 train_loss= 8.14741
Epoch: 0030 train_loss= 8.14720
Epoch: 0040 train_loss= 8.14716
Epoch: 0050 train_loss= 8.14715
Epoch: 0060 train_loss= 8.14714
Epoch: 0070 train_loss= 8.14714
Epoch: 0080 train_loss= 8.14714
Epoch: 0090 train_loss= 8.14713
Epoch: 0100 train_loss= 8.14713
0.7815314975842763
Epoch: 0110 train_loss= 8.14713
Epoch: 0120 train_loss= 8.14713
Epoch: 0130 train_loss= 8.14713
Epoch: 0140 train_loss= 8.14713
Epoch: 0150 train_loss= 8.14713
Epoch: 0160 train_loss= 8.14713
Epoch: 0170 train_loss= 8.14713
Epoch: 0180 train_loss= 8.14713
Epoch: 0190 train_loss= 8.14713
Epoch: 0200 train_loss= 8.14713
0.7815345806122757
Epoch: 0210 train_loss= 8.14713
Epoch: 0220 train_loss= 8.14713
Epoch: 0230 train_loss= 8.14713
Epoch: 0240 train_loss= 8.14713
Epoch: 0250 train_loss= 8.14713
Epoch: 0260 train_loss= 8.14713
Epoch: 0270 train_loss= 8.14713
Epoch: 0280 train_loss= 8.14713
Epoch: 0290 train_loss= 8.14713
Epoch: 0300 train_loss= 8.14713
0.7815345806122758


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 9269.82422
Epoch: 0020 train_loss= 9254.96973
Epoch: 0030 train_loss= 9252.85254
Epoch: 0040 train_loss= 9228.67871
Epoch: 0050 train_loss= 9249.54004
Epoch: 0060 train_loss= 9227.12012
Epoch: 0070 train_loss= 9228.93066
Epoch: 0080 train_loss= 9222.47656
Epoch: 0090 train_loss= 9229.33691
Epoch: 0100 train_loss= 9234.73633
0.4703389830508475
Epoch: 0110 train_loss= 9226.83691
Epoch: 0120 train_loss= 9224.20703
Epoch: 0130 train_loss= 9254.01758
Epoch: 0140 train_loss= 9222.75000
Epoch: 0150 train_loss= 9220.75000
Epoch: 0160 train_loss= 9217.50488
Epoch: 0170 train_loss= 9214.13184
Epoch: 0180 train_loss= 9210.84082
Epoch: 0190 train_loss= 9208.40234
Epoch: 0200 train_loss= 9205.75488
0.4731638418079096
Epoch: 0210 train_loss= 9204.40918
Epoch: 0220 train_loss= 9202.07129
Epoch: 0230 train_loss= 9200.77051
Epoch: 0240 train_loss= 9199.23633
Epoch: 0250 train_loss= 9199.58398
Epoch: 0260 train_loss= 9196.16504
Epoch: 0270 train_loss= 9206.87109
Epoch: 0280 train_loss= 9219.39355
Epoch: 0290 train_loss= 9204.64551
Epoch: 0300 train_loss= 9203.86621
0.4731638418079096


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 907434304.00000
Epoch: 0020 train_loss= 907434624.00000
Epoch: 0030 train_loss= 907366592.00000
Epoch: 0040 train_loss= 907365056.00000
Epoch: 0050 train_loss= 907369600.00000
Epoch: 0060 train_loss= 907373568.00000
Epoch: 0070 train_loss= 907365888.00000
Epoch: 0080 train_loss= 907364800.00000
Epoch: 0090 train_loss= 907367872.00000
Epoch: 0100 train_loss= 907365312.00000
0.6905529272619753
Epoch: 0110 train_loss= 907386176.00000
Epoch: 0120 train_loss= 907366912.00000
Epoch: 0130 train_loss= 907365568.00000
Epoch: 0140 train_loss= 907365888.00000
Epoch: 0150 train_loss= 907365504.00000
Epoch: 0160 train_loss= 907366848.00000
Epoch: 0170 train_loss= 907364032.00000
Epoch: 0180 train_loss= 907362752.00000
Epoch: 0190 train_loss= 907367744.00000
Epoch: 0200 train_loss= 907365824.00000
0.6910999408633945
Epoch: 0210 train_loss= 907360384.00000
Epoch: 0220 train_loss= 907366080.00000
Epoch: 0230 train_loss= 907370624.00000
Epoch: 0240 train_loss= 907363840.00000
Epoch: 0250 train_loss= 907361280.00000
Epoch: 0260 train_loss= 907360704.00000
Epoch: 0270 train_loss= 907361216.00000
Epoch: 0280 train_loss= 907360576.00000
Epoch: 0290 train_loss= 907360384.00000
Epoch: 0300 train_loss= 907360064.00000
0.6902424600827912


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 9.64829
Epoch: 0020 train_loss= 9.64827
Epoch: 0030 train_loss= 9.64829
Epoch: 0040 train_loss= 9.64821
Epoch: 0050 train_loss= 9.64820
Epoch: 0060 train_loss= 9.64819
Epoch: 0070 train_loss= 9.64818
Epoch: 0080 train_loss= 9.64839
Epoch: 0090 train_loss= 9.64831
Epoch: 0100 train_loss= 9.64826
0.7510925508612131
Epoch: 0110 train_loss= 9.64818
Epoch: 0120 train_loss= 9.64818
Epoch: 0130 train_loss= 9.64814
Epoch: 0140 train_loss= 9.64839
Epoch: 0150 train_loss= 9.64813
Epoch: 0160 train_loss= 9.64805
Epoch: 0170 train_loss= 9.64801
Epoch: 0180 train_loss= 9.64797
Epoch: 0190 train_loss= Traceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
9.64801
Epoch: 0200 train_loss= 9.64791
0.750577398868525
Epoch: 0210 train_loss= 9.64787
Epoch: 0220 train_loss= 9.64782
Epoch: 0230 train_loss= 9.64778
Epoch: 0240 train_loss= 9.64770
Epoch: 0250 train_loss= 9.64762
Epoch: 0260 train_loss= 9.64755
Epoch: 0270 train_loss= 9.64746
Epoch: 0280 train_loss= 9.64740
Epoch: 0290 train_loss= 9.64741
Epoch: 0300 train_loss= 9.64728
0.7491838567849094


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 9.91139
Epoch: 0020 train_loss= 9.72913
Epoch: 0030 train_loss= 9.66412
Epoch: 0040 train_loss= 9.60910
Epoch: 0050 train_loss= 9.54613
Epoch: 0060 train_loss= 9.54816
Epoch: 0070 train_loss= 9.54368
Epoch: 0080 train_loss= 9.54370
Epoch: 0090 train_loss= 9.54335
Epoch: 0100 train_loss= 9.54335
0.48668938326842875
Epoch: 0110 train_loss= 9.54331
Epoch: 0120 train_loss= 9.54331
Epoch: 0130 train_loss= 9.54330
Epoch: 0140 train_loss= 9.54330
Epoch: 0150 train_loss= 9.54330
Epoch: 0160 train_loss= 9.54330
Epoch: 0170 train_loss= 9.54330
Epoch: 0180 train_loss= 9.54330
Epoch: 0190 train_loss= 9.54330
Epoch: 0200 train_loss= 9.54330
0.48664575785194725
Epoch: 0210 train_loss= 9.54330
Epoch: 0220 train_loss= 9.54330
Epoch: 0230 train_loss= 9.54330
Epoch: 0240 train_loss= 9.54330
Epoch: 0250 train_loss= 9.54330
Epoch: 0260 train_loss= 9.54330
Epoch: 0270 train_loss= 9.54330
Epoch: 0280 train_loss= 9.54330
Epoch: 0290 train_loss= 9.54330
Epoch: 0300 train_loss= 9.54330
0.48664293318469304


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.8, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 14.33615
Epoch: 0020 train_loss= 14.32947
Epoch: 0030 train_loss= 14.32827
Epoch: 0040 train_loss= 14.32821
Epoch: 0050 train_loss= 14.32814
Epoch: 0060 train_loss= 14.32812
Epoch: 0070 train_loss= 14.32809
Epoch: 0080 train_loss= 14.32805
Epoch: 0090 train_loss= 14.32800
Epoch: 0100 train_loss= 14.32793
