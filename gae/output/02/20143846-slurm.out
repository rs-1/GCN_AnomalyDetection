
The following have been reloaded with a version change:
  1) GCC/4.9.2 => GCC/6.2.0
  2) Python/2.7.9-intel-2016.u3 => Python/2.7.13-intel-2017.u2
  3) SQLite/3.8.11.1-intel-2016.u3 => SQLite/3.13.0-intel-2017.u2
  4) Tcl/8.6.5-intel-2016.u3 => Tcl/8.6.5-intel-2017.u2
  5) Tk/8.6.5-intel-2016.u3 => Tk/8.6.5-intel-2017.u2
  6) bzip2/1.0.6-intel-2016.u3 => bzip2/1.0.6-intel-2017.u2
  7) icc/2016.u3-GCC-4.9.2 => icc/2017.u2-GCC-6.2.0
  8) iccifort/2016.u3-GCC-4.9.2 => iccifort/2017.u2-GCC-6.2.0
  9) ifort/2016.u3-GCC-4.9.2 => ifort/2017.u2-GCC-6.2.0
 10) iimpi/2016.u3-GCC-4.9.2 => iimpi/2017.u2-GCC-6.2.0
 11) imkl/11.3.3.210-iimpi-2016.u3-GCC-4.9.2 => imkl/2017.2.174-iimpi-2017.u2-GCC-6.2.0
 12) impi/5.1.3.223-iccifort-2016.u3-GCC-4.9.2 => impi/2017.2.174-iccifort-2017.u2-GCC-6.2.0
 13) intel/2016.u3 => intel/2017.u2
 14) libffi/3.2.1-intel-2016.u3 => libffi/3.2.1-intel-2017.u2
 15) libreadline/6.3-intel-2016.u3 => libreadline/6.3-intel-2017.u2
 16) ncurses/5.9-intel-2016.u3 => ncurses/6.0-intel-2017.u2
 17) zlib/1.2.8-intel-2016.u3 => zlib/1.2.8-intel-2017.u2

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: spartan-gpgpu036.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: spartan-gpgpu036.hpc.unimelb.edu.au
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.51.05  Sun Jun 28 10:33:40 UTC 2020
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) 
"""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 450.51.5
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 450.51.5
---------------------------------------- acm_test_final ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 20.27312
Epoch: 0020 train_loss= 20.11441
Epoch: 0030 train_loss= 20.09279
Epoch: 0040 train_loss= 20.08833
Epoch: 0050 train_loss= 20.08694
Epoch: 0060 train_loss= 20.08636
Epoch: 0070 train_loss= 20.08613
Epoch: 0080 train_loss= 20.08598
Epoch: 0090 train_loss= 20.08587
Epoch: 0100 train_loss= 20.08577
0.7752005088934242
Epoch: 0110 train_loss= 20.08566
Epoch: 0120 train_loss= 20.08556
Epoch: 0130 train_loss= 20.08546
Epoch: 0140 train_loss= 20.08536
Epoch: 0150 train_loss= 20.08526
Epoch: 0160 train_loss= 20.08516
Epoch: 0170 train_loss= 20.08505
Epoch: 0180 train_loss= 20.08495
Epoch: 0190 train_loss= 20.08484
Epoch: 0200 train_loss= 20.08472
0.7745867083067188
Epoch: 0210 train_loss= 20.08460
Epoch: 0220 train_loss= 20.08448
Epoch: 0230 train_loss= 20.08435
Epoch: 0240 train_loss= 20.08423
Epoch: 0250 train_loss= 20.08410
Epoch: 0260 train_loss= 20.08397
Epoch: 0270 train_loss= 20.08385
Epoch: 0280 train_loss= 20.08372
Epoch: 0290 train_loss= 20.08360
Epoch: 0300 train_loss= 20.08348
0.7754022493880942


---------------------------------------- Amazon ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 21
Epoch: 0010 train_loss= 129316.03125
Epoch: 0020 train_loss= 129313.75000
Epoch: 0030 train_loss= 129313.47656
Epoch: 0040 train_loss= 129313.45312
Epoch: 0050 train_loss= 129313.56250
Epoch: 0060 train_loss= 129313.44531
Epoch: 0070 train_loss= 129315.63281
Epoch: 0080 train_loss= 129313.55469
Epoch: 0090 train_loss= 129315.34375
Epoch: 0100 train_loss= 129314.29688
0.6238566289825282
Epoch: 0110 train_loss= 129316.65625
Epoch: 0120 train_loss= 129313.42188
Epoch: 0130 train_loss= 129315.21094
Epoch: 0140 train_loss= 129314.27344
Epoch: 0150 train_loss= 129313.40625
Epoch: 0160 train_loss= 129314.81250
Epoch: 0170 train_loss= 129313.51562
Epoch: 0180 train_loss= 129315.20312
Epoch: 0190 train_loss= 129314.32812
Epoch: 0200 train_loss= 129313.42969
0.6256166495375128
Epoch: 0210 train_loss= 129314.26562
Epoch: 0220 train_loss= 129316.50781
Epoch: 0230 train_loss= 129315.21094
Epoch: 0240 train_loss= 129317.00781
Epoch: 0250 train_loss= 129314.25000
Epoch: 0260 train_loss= 129313.53125
Epoch: 0270 train_loss= 129315.56250
Epoch: 0280 train_loss= 129314.41406
Epoch: 0290 train_loss= 129314.77344
Epoch: 0300 train_loss= 129313.61719
0.6260534429599178


---------------------------------------- BlogCatalog ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 8189
Epoch: 0010 train_loss= 11.63417
Epoch: 0020 train_loss= 11.63370
Epoch: 0030 train_loss= 11.63355
Epoch: 0040 train_loss= 11.63341
Epoch: 0050 train_loss= 11.63329
Epoch: 0060 train_loss= 11.63337
Epoch: 0070 train_loss= 11.63339
Epoch: 0080 train_loss= 11.63319
Epoch: 0090 train_loss= 11.63311
Epoch: 0100 train_loss= 11.63305
0.783041496186637
Epoch: 0110 train_loss= 11.63303
Epoch: 0120 train_loss= 11.63301
Epoch: 0130 train_loss= 11.63290
Epoch: 0140 train_loss= 11.63298
Epoch: 0150 train_loss= 11.63280
Epoch: 0160 train_loss= 11.63273
Epoch: 0170 train_loss= 11.63267
Epoch: 0180 train_loss= 11.63257
Epoch: 0190 train_loss= 11.63252
Epoch: 0200 train_loss= 11.63249
0.782879808496003
Epoch: 0210 train_loss= 11.63244
Epoch: 0220 train_loss= 11.63242
Epoch: 0230 train_loss= 11.63245
Epoch: 0240 train_loss= 11.63229
Epoch: 0250 train_loss= 11.63227
Epoch: 0260 train_loss= 11.63232
Epoch: 0270 train_loss= 11.63262
Epoch: 0280 train_loss= 11.63220
Epoch: 0290 train_loss= 11.63213
Epoch: 0300 train_loss= 11.63206
0.782909611099997


---------------------------------------- Disney ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 28
Epoch: 0010 train_loss= 7949.69385
Epoch: 0020 train_loss= 7902.23193
Epoch: 0030 train_loss= 7794.97949
Epoch: 0040 train_loss= 7671.20117
Epoch: 0050 train_loss= 7611.73779
Epoch: 0060 train_loss= 7557.07910
Epoch: 0070 train_loss= 7457.86084
Epoch: 0080 train_loss= 7435.12695
Epoch: 0090 train_loss= 7426.95020
Epoch: 0100 train_loss= 7447.05371
0.557909604519774
Epoch: 0110 train_loss= 7404.84912
Epoch: 0120 train_loss= 7391.58691
Epoch: 0130 train_loss= 7387.58496
Epoch: 0140 train_loss= 7362.57617
Epoch: 0150 train_loss= 7338.79053
Epoch: 0160 train_loss= 7328.50586
Epoch: 0170 train_loss= 7334.81201
Epoch: 0180 train_loss= 7314.36182
Epoch: 0190 train_loss= 7372.91846
Epoch: 0200 train_loss= 7300.40674
0.5494350282485876
Epoch: 0210 train_loss= 7295.12012
Epoch: 0220 train_loss= 7269.68555
Epoch: 0230 train_loss= 7259.87744
Epoch: 0240 train_loss= 7245.68311
Epoch: 0250 train_loss= 7238.61475
Epoch: 0260 train_loss= 7224.40771
Epoch: 0270 train_loss= 7199.73047
Epoch: 0280 train_loss= 7187.79150
Epoch: 0290 train_loss= 7167.90723
Epoch: 0300 train_loss= 7149.90234
0.5437853107344632


---------------------------------------- Enron ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 18
Epoch: 0010 train_loss= 794085696.00000
Epoch: 0020 train_loss= 794141888.00000
Epoch: 0030 train_loss= 793952832.00000
Epoch: 0040 train_loss= 793944896.00000
Epoch: 0050 train_loss= 793947904.00000
Epoch: 0060 train_loss= 793948352.00000
Epoch: 0070 train_loss= 793946752.00000
Epoch: 0080 train_loss= 793944000.00000
Epoch: 0090 train_loss= 793944704.00000
Epoch: 0100 train_loss= 793943872.00000
0.6906268480189237
Epoch: 0110 train_loss= 793944448.00000
Epoch: 0120 train_loss= 793943360.00000
Epoch: 0130 train_loss= 793943104.00000
Epoch: 0140 train_loss= 793942528.00000
Epoch: 0150 train_loss= 794465472.00000
Epoch: 0160 train_loss= 793944960.00000
Epoch: 0170 train_loss= 793951936.00000
Epoch: 0180 train_loss= 793947712.00000
Epoch: 0190 train_loss= 793946112.00000
Epoch: 0200 train_loss= 793945600.00000
0.6909077468953282
Epoch: 0210 train_loss= 793943872.00000
Epoch: 0220 train_loss= 793967296.00000
Epoch: 0230 train_loss= 793951168.00000
Epoch: 0240 train_loss= 793944256.00000
Epoch: 0250 train_loss= 793941376.00000
Epoch: 0260 train_loss= 793941184.00000
Epoch: 0270 train_loss= 794187136.00000
Epoch: 0280 train_loss= 793939584.00000
Epoch: 0290 train_loss= 793955776.00000
Epoch: 0300 train_loss= 793966080.00000
0.6881283264340627


---------------------------------------- Flickr1 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 13.88188
Epoch: 0020 train_loss= 13.88183
Epoch: 0030 train_loss= 13.88181
Epoch: 0040 train_loss= 13.88181
Epoch: 0050 train_loss= 13.88179
Epoch: 0060 train_loss= 13.88178
Epoch: 0070 train_loss= 13.88176
Epoch: 0080 train_loss= 13.88185
Epoch: 0090 train_loss= 13.88173
Epoch: 0100 train_loss= 13.88167
0.752191877964606
Epoch: 0110 train_loss= 13.88161
Epoch: 0120 train_loss= 13.88154
Epoch: 0130 train_loss= 13.88149
Epoch: 0140 train_loss= 13.88144
Epoch: 0150 train_loss= 13.88126
Epoch: 0160 train_loss= 13.88127
Epoch: 0170 train_loss= 13.88135
Epoch: 0180 trTraceback (most recent call last):
  File "run.py", line 60, in <module>
    runner.erun()
  File "/data/gpfs/projects/punim1343/repo/GCN_AnomalyDetection/gae/anomaly_detection.py", line 55, in erun
    auc = roc_auc_score(y_true, reconstruction_errors)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/ranking.py", line 260, in roc_auc_score
    sample_weight=sample_weight)
  File "/usr/local/easybuild/software/scikit-learn/0.18-intel-2016.u3-Python-2.7.9/lib/python2.7/site-packages/sklearn/metrics/base.py", line 81, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: multiclass format is not supported
ain_loss= 13.88116
Epoch: 0190 train_loss= 13.88101
Epoch: 0200 train_loss= 13.88063
0.7495830247254047
Epoch: 0210 train_loss= 13.88036
Epoch: 0220 train_loss= 13.88023
Epoch: 0230 train_loss= 13.87984
Epoch: 0240 train_loss= 13.87998
Epoch: 0250 train_loss= 13.87932
Epoch: 0260 train_loss= 13.87963
Epoch: 0270 train_loss= 13.87946
Epoch: 0280 train_loss= 13.87879
Epoch: 0290 train_loss= 13.87835
Epoch: 0300 train_loss= 13.87780
0.7480104637786218


---------------------------------------- Flickr2 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 20
Epoch: 0010 train_loss= 14.09391
Epoch: 0020 train_loss= 13.84914
Epoch: 0030 train_loss= 13.81545
Epoch: 0040 train_loss= 13.81229
Epoch: 0050 train_loss= 13.81033
Epoch: 0060 train_loss= 13.81014
Epoch: 0070 train_loss= 13.80985
Epoch: 0080 train_loss= 13.80980
Epoch: 0090 train_loss= 13.80979
Epoch: 0100 train_loss= 13.80978
0.49122313113737426
Epoch: 0110 train_loss= 13.80978
Epoch: 0120 train_loss= 13.80978
Epoch: 0130 train_loss= 13.80978
Epoch: 0140 train_loss= 13.80978
Epoch: 0150 train_loss= 13.80978
Epoch: 0160 train_loss= 13.80978
Epoch: 0170 train_loss= 13.80978
Epoch: 0180 train_loss= 13.80978
Epoch: 0190 train_loss= 13.80978
Epoch: 0200 train_loss= 13.80978
0.4912403929928165
Epoch: 0210 train_loss= 13.80978
Epoch: 0220 train_loss= 13.80978
Epoch: 0230 train_loss= 13.80978
Epoch: 0240 train_loss= 13.80978
Epoch: 0250 train_loss= 13.80978
Epoch: 0260 train_loss= 13.80978
Epoch: 0270 train_loss= 13.80978
Epoch: 0280 train_loss= 13.80978
Epoch: 0290 train_loss= 13.80978
Epoch: 0300 train_loss= 13.80978
0.4912396083630237


---------------------------------------- Flickr3 ----------------------------------------
{'hidden3': 16, 'hidden2': 32, 'hidden1': 64, 'features': 1, 'learning_rate': 0.005, 'discriminator_out': 0, 'discriminator_learning_rate': 0.005, 'iterations': 300, 'alpha': 0.7, 'weight_decay': 0.0, 'dropout': 0.0}
feature number: 12047
Epoch: 0010 train_loss= 17.98067
Epoch: 0020 train_loss= 17.97721
Epoch: 0030 train_loss= 17.97698
Epoch: 0040 train_loss= 17.97693
Epoch: 0050 train_loss= 17.97688
Epoch: 0060 train_loss= 17.97683
Epoch: 0070 train_loss= 17.97673
Epoch: 0080 train_loss= 17.97652
Epoch: 0090 train_loss= 17.97630
Epoch: 0100 train_loss= 17.97719
